{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04 â€“ Classification\n",
    "\n",
    "In this exercise, we will train a classification model to predict categorical targets.\n",
    "\n",
    "Note: make sure to run all Code cells from the beginning at least once to load the required data. Use `random_state=42` where random numbers are used to ensure determinism, i.e. reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The MNIST handwritten digits dataset\n",
    "\n",
    "For this exercise we will use the famous MNIST digits dataset, which was presented in the lecture. The task is to classify images of 28x28 pixels into one of the 10 classes (digits 0 to 9).\n",
    "\n",
    "Scikit-learn can easily load the dataset for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'categories', 'feature_names', 'target_names', 'DESCR', 'details', 'url'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784', version=1) # ('MNIST original')\n",
    "mnist.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X, y = mnist[\"data\"], mnist[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (60000,))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]\n",
    "\n",
    "## MNIST is already shuffled (see HOML2 S. 91)\n",
    "# from sklearn.utils import shuffle\n",
    "# X_train, y_train = shuffle(X_train, y_train)\n",
    "\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a sense of the data, we'll look at one of the training samples. As you can see, the images are rows of 784 elements in the `X` matrix, so we have to reshape it to the original 28x28 image for plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "some_digit = X[36000]\n",
    "some_digit_image = some_digit.reshape(28, 28)\n",
    "plt.imshow(some_digit_image, cmap = matplotlib.cm.binary, interpolation=\"nearest\")\n",
    "plt.axis(\"off\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[36000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the labels are stored as strings, not as numbers. So let's convert those to integers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = y.astype(np.uint8)\n",
    "y[36000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Use python to inspect the MNIST dataset you downloaded above concerning its number of instances (available for training and testing), number of features and their value ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "1. How many instances has the MNIST dataset?\n",
    "2. How many features has the MNIST dataset? Why?\n",
    "3. What is the value range of the features of the MNIST dataset? Why?\n",
    "4. How many label does the dataset have?\n",
    "5. Are we bound to use semi-supervised learning methods?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer\n",
    "\n",
    "1. 70000\n",
    "2. 784 : Each image consists of 784 pixels\n",
    "3. von 0 bis 255 :  gray-scale (0 - 255)\n",
    "4. 255\n",
    "5. nein  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Train a simple `SGDClassifier` with `loss=\"hinge\", random_state=42` (default parameters otherwise) on the training set and compute the [F1-Score](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html) **per class** on the test set.\\\n",
    "Time both the execution of the training and the testing using `%time` before the actual code line.\n",
    "\n",
    "Then [plot](https://matplotlib.org/api/_as_gen/matplotlib.pyplot.matshow.html) the test set [confusion matrix](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html), with rows being the true class and columns being the predicted classes. \n",
    "\n",
    "*Hint:* set the diagonal elements of the matrix [to zero](https://docs.scipy.org/doc/numpy-1.15.0/reference/generated/numpy.fill_diagonal.html) to make the errors more visible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 15s\n",
      "Wall time: 25 ms\n",
      "Wall time: 29 ms\n"
     ]
    }
   ],
   "source": [
    "## train SGD and then predict labels for the test set \n",
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd=SGDClassifier(loss=\"hinge\", random_state=42)\n",
    "\n",
    "%time sgd.fit(X_train, y_train)\n",
    "%time sgd.predict(X_test)\n",
    "%time y_pred=sgd.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.94847529, 0.96859797, 0.8474934 , 0.84406165, 0.86927374,\n",
       "       0.82537835, 0.92574526, 0.91215881, 0.7520483 , 0.85602733])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## F1-score\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_test, y_pred, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "## generate confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cmat=confusion_matrix(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<matplotlib.image.AxesImage at 0x1c381e38490>,\n",
       " Text(0, 0.5, 'true'),\n",
       " Text(0.5, 0, 'Predicted'))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## plot confusion matrix\n",
    "np.fill_diagonal(cmat,0)\n",
    "matshow(cmat), ylabel(\"true\"),xlabel(\"Predicted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "- Looking at your confusion matrix, which seems to be the most common mistake of the classifier? \n",
    "- Why do you think it makes this mistake?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer\n",
    "\n",
    "2-8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Now use the function of scikit-learn to do a 4-fold CV on the same classifier, with `scoring=\"accuracy\"` and `n_jobs=-1` to make use of all your CPU cores and time the execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 6s\n"
     ]
    }
   ],
   "source": [
    "## CV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "%time scores = cross_val_score(sgd,X,y, scoring=\"accuracy\",n_jobs=-1,cv=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question\n",
    "\n",
    "Independent of your timing result: On a machine with 4 CPU cores the 4-fold CV is generally faster than the training with `clf.fit(X_train, y_train)`.\\\n",
    "Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "Now scale the data to zero mean and unit variance. Use the scikit-learn function `StandardScaler` for that.\\\n",
    "Then run 4-fold CV again and plot the confusion matrix (as above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "## scale features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler= StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_transformed = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 46s\n",
      "Wall time: 32 ms\n",
      "Wall time: 30 ms\n"
     ]
    }
   ],
   "source": [
    "## CV/train SGD from above again with scaled features\n",
    "%time sgd.fit(X_train_scaled, y_train)\n",
    "%time sgd.predict(X_test_transformed)\n",
    "%time y_pred=sgd.predict(X_test_transformed)\n",
    "scores = cross_val_score(sgd,X,y, scoring=\"accuracy\",n_jobs=-1,cv=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<matplotlib.image.AxesImage at 0x1c3e9c4b6a0>,\n",
       " Text(0, 0.5, 'True'),\n",
       " Text(0.5, 0, 'Predicted'))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## confusion matrix plot\n",
    "cmat=confusion_matrix(y_test, y_pred)\n",
    "np.fill_diagonal(cmat,0)\n",
    "matshow(cmat), ylabel(\"True\"),xlabel(\"Predicted\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "1. Which learning algorithm does the `SGDClassifier` use under the hood in this example? \n",
    "2. Why does the scaling improve the result?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Train a `DecisionTreeClassifier` (dt) on the training set and compute the `macro` averaged F1-Score on the test set. **Make sure to avoid overfitting by using the regularization hyper-parameters!** (You can also use GridSearch to find good parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train dt and then predict labels for the test set\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier(min_samples_leaf=4)\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred_dt = dt.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8792083023911912"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## averaged F1-Score on the test set\n",
    "f1_score(y_test, y_pred_dt, average=\"macro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Train a Random Forest classifier `RandomForestClassifier` (rf) and an Extra-Trees classifier `ExtraTreesClassifier` (et), each with 100 estimators and `random_state=42` (for determinism)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "## instanciate rf and et\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "rf=RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "et=ExtraTreesClassifier(n_estimators=100, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(random_state=42)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## train rf and et \n",
    "rf.fit(X_train, y_train)\n",
    "et.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "## predict labels for the test set\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "y_pred_et = et.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Compute the `accuracy_score` on the test set for each of the 4 classifiers from Exercise 1-4.\n",
    "\n",
    "Then, combine the 4 classifiers into one `VotingClassifier` (vc) ensemble and compute the accuracy on the test set for this ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9722"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## socre all\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred)\n",
    "accuracy_score(y_test, y_pred_dt)\n",
    "accuracy_score(y_test, y_pred_rf)\n",
    "accuracy_score(y_test, y_pred_et)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train vc\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "vc=VotingClassifier(estimators=[('sgd',sgd), ('dt', dt), ('rf', rf),('et', et)], voting='hard')\n",
    "vc= vc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9688"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## predict labels for the test set\n",
    "y_pred_vc = vc.predict(X_test)\n",
    "accuracy_score(y_test, y_pred_vc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question\n",
    "\n",
    "All four classifiers in the ensemble were trained on the same dataset (ie., no bagging, pasting, boosting). Could an ensemble still achieve a higher prediction accuracy than the individual classifiers (regardless of whether it actually happened here)? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional\n",
    "\n",
    "Construct a Gaussian kernel [Support Vector Machine](http://scikit-learn.org/stable/modules/svm.html) with `C=5, gamma=0.05` and check if the `VotingClassifier` can be improved with that additional classifier (this increases the compute time by about 30 minutes or longer)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
